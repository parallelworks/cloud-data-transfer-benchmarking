{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06aad8f1",
   "metadata": {},
   "source": [
    "# Cloud Data Transfer Speeds Benchmarking Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28551822",
   "metadata": {},
   "source": [
    "Add overview of workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb52c47",
   "metadata": {},
   "source": [
    "## Step 0: Load Required Setup Packages & Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e427e0",
   "metadata": {},
   "source": [
    "Enter the following parameters to install packages to the correct conda instance and environment.\n",
    "\n",
    "\n",
    "`jupyter_conda_path : str`\n",
    "    - The path to miniconda that this Jupyter notebook is running from. Do not include a terminal `/` at the end of the path.\n",
    "    \n",
    "`jupyter_conda_env : str`\n",
    "    - The conda environment that this Jupyter notebook is running in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f93cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_conda_path = \"/home/jgreen/.miniconda3c\"\n",
    "jupyter_conda_env = \"jupyter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9c4fe",
   "metadata": {},
   "source": [
    "Installs required workflow setup packages and calls UI generation script. If one or more of the packages don't exist in the specified environment, they will install for you. Note that if installation is required, this cell will take a few minutes to complete execution.\n",
    "\n",
    "**NOTE: If you recieve an import error for `jupyter-ui-poll`, you will have to manually install the package in a user container terminal with the following commands:**\n",
    "```\n",
    "source <jupyter_conda_path>/etc/profile.d/conda.sh\n",
    "conda activate <jupyter_conda_env>\n",
    "pip install jupyter-ui-poll\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73185f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking conda environment for UI depedencies...\n",
      "All dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "print('Checking conda environment for UI depedencies...')\n",
    "os.system(\"bash \" + os.getcwd() + f\"/jupyter-helpers/install_ui_packages.sh {jupyter_conda_path} {jupyter_conda_env}\")\n",
    "print('All dependencies installed.')\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + '/jupyter-helpers')\n",
    "import ui_helpers as ui\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be35fd4",
   "metadata": {},
   "source": [
    "## Step 1: Define Workflow Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de7e39",
   "metadata": {},
   "source": [
    "Run the following cells to generate interactive widgets allowing you to enter all workflow inputs. **All inputs must be filled out to proceed with the benchmarking process.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cb664",
   "metadata": {},
   "source": [
    "### Cloud Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e7e51",
   "metadata": {},
   "source": [
    "#### Compute Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26d055",
   "metadata": {},
   "source": [
    "Before defining anything else, the resources you intend to use with the benchmarking must be defined. Currently, only resources defined in the Parallel Works platform may be used. Also of note are options that will be passed to Dask: you have full control over how many cores and memory you want each worker from your cluster to use, as well as how many nodes you want to be active at a single time.\n",
    "\n",
    "In particular, these options are included so that you can form fair comparisons between different cloud service providers (CSPs). Generally, different CSPs won't have worker nodes with the exact same specs, and in order to achieve a fair comparison between two CSPs one cluster will have to limited to not exceed to the computational power of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9376e50",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "For resources controlled from the Parallel Works platform, the <code>Resource name</code> box should be populated with the name found on the <b>RESOURCES</b>  tab.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21753c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Add field', style=ButtonStyle()), Button(description='Remove field', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HBox(children=(Label(value='Resource Name: '), Text(value=''))), HBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "If you wish to change information about cloud resources, run this cell again.\n",
      "\n",
      "Your resource inputs:\n",
      " [{'Name': 'gcptestnew', 'CSP': 'GCP', 'Dask': {'Scheduler': 'SLURM', 'Partition': 'compute', 'CPUs': 2, 'Memory': 16.0}}]\n"
     ]
    }
   ],
   "source": [
    "resource = ui.resourceWidgets()\n",
    "resource.display()\n",
    "resources = resource.processInput()\n",
    "print(f'Your resource inputs:\\n {resources}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4fe8c",
   "metadata": {},
   "source": [
    "#### Object Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea7fb6",
   "metadata": {},
   "source": [
    "This set of inputs is where you enter the cloud object store Universal Resource Identifiers (URIs). Both public and private buckets are supported. For the latter, ensure that you have access credentials with *at least* read, write, list, and put (copy from local storage to cloud) permissions, as format conversions will need to be made during the benchmarking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b144152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Add field', style=ButtonStyle()), Button(description='Remove field', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HBox(children=(Label(value='Storage URI: '), Text(value='', placeholder='gc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "If you wish to change information about cloud storage locations, run this cell again.\n",
      "\n",
      "Your storage inputs:\n",
      " [{'Path': 'gs://cloud-data-benchmarks', 'Type': 'Private', 'CSP': 'GCP', 'Credentials': {'token': './.cloud-data-benchmarks.json'}}, {'Path': 's3://cloud-data-benchmarks', 'Type': 'Private', 'CSP': 'AWS', 'Credentials': {'anon': False, 'key': 'AKIARQNWZVPER5LAPF27', 'secret': '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'}}]\n"
     ]
    }
   ],
   "source": [
    "store = ui.storageWidgets()\n",
    "store.display()\n",
    "storage = store.processInput()\n",
    "print(f'Your storage inputs:\\n {storage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8711e2b",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2323384",
   "metadata": {},
   "source": [
    "#### User-Supplied Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bd7e0",
   "metadata": {},
   "source": [
    "Below you can specify datasets that you want to be tested in the benchmarking. You can either enter single files or multiple files that belong to a single dataset, but that dataset match at least one of the supported formats. **Read the following input rules after running the UI cell below this one.**\n",
    "\n",
    "\n",
    "1. Activate the checkbox if you desire to record your user-defined datasets. If it is not checked, none of your inputs will be recorded.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Input the full URI or absolute path of the data location (`<URI prefix>://bucket-name/path/to/file.extension` or `/path/to/file.extension`)\n",
    "    - Use globstrings (`<URI prefix>://bucket-name/path/to/files/*` or `path/to/files/*`) to specify datasets that are split up into multiple subfiles.\n",
    "    - If using a globstring, ensure that *only* files that belong to the dataset exist in that directory. The workflow will take all files in the directory before the `*` and attempt to gather them into a single dataset.\n",
    "    - **Globstrings are NOT supported for NetCDF files**\n",
    "    \n",
    "<br>\n",
    "\n",
    "3. If you have a dataset stored in multiple cloud storage locations that will be used in the benchmarking, you must input the full URI of that dataset for each of these locations. That is, you must define each location of the data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0baaed80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Provide datasets to workflow?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Add field', style=ButtonStyle()), Button(description='Remove field', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HBox(children=(Label(value='Data Format'), Dropdown(options=('CSV', 'NetCDF…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "If you wish to change information about your input data, run this cell again.\n",
      "\n",
      "Your data inputs:\n",
      " [{'Format': 'NetCDF4', 'SourcePath': 'gs://cloud-data-benchmarks/ETOPO1_Ice_g_gmt4.nc', 'Type': 'Private', 'CSP': 'GCP', 'Credentials': {'token': './.cloud-data-benchmarks.json'}}, {'Format': 'NetCDF4', 'SourcePath': 's3://cloud-data-benchmarks/ETOPO1_Ice_g_gmt4.nc', 'Type': 'Private', 'CSP': 'AWS', 'Credentials': {'anon': False, 'key': 'AKIARQNWZVPER5LAPF27', 'secret': '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'}}]\n"
     ]
    }
   ],
   "source": [
    "userdata = ui.userdataWidgets(storage=storage)\n",
    "userdata.display()\n",
    "user_files = userdata.processInput()\n",
    "print(f'Your data inputs:\\n {user_files}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4c5eb",
   "metadata": {},
   "source": [
    "#### Randomly-Generated Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322692c1",
   "metadata": {},
   "source": [
    "Another option to supply data to the benchmarking is to create randomly-generated datasets. These sets can be as large as you want (as they are written in parallel), and provide a great option if you are new to the world of cloud-native data formats. There are currently two supported randomly-generated data formats: CSV and NetCDF4. Since NetCDF4 is a gridded data format, an option to specify the number of coordinate axes is also included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdf672",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Randomly-generated NetCDF4 file sizes are limited by available disk space in the cluster you are generating the file with. Ensure that you have adequate disk space in your cluster, or the file will not fully generate.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46825cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HBox(children=(Label(value='Resource to write random files with: '), Dropdown(options=('gc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------\n",
      "If you wish to change the randomly generated file options, run this cell again.\n",
      "\n",
      "Your randomly-generated file options:\n",
      " [{'Format': 'CSV', 'Generate': False, 'SizeGB': 0.0}, {'Format': 'NetCDF4', 'Generate': True, 'SizeGB': 10.0, 'Data Variables': 2.0, 'Float Coords': 3.0}, {'Resource': 'gcptestnew'}]\n"
     ]
    }
   ],
   "source": [
    "randgen = ui.randgenWidgets(resources=resources)\n",
    "randgen.display()\n",
    "randfiles = randgen.processInput()\n",
    "print(f'Your randomly-generated file options:\\n {randfiles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612fa1",
   "metadata": {},
   "source": [
    "### TODO: Cloud-Native Format Conversion Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581d0ee",
   "metadata": {},
   "source": [
    "**Feature not ready**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d585b",
   "metadata": {},
   "source": [
    "## Step 2: Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f2c55",
   "metadata": {},
   "source": [
    "Executing the following cell will write all of your inputs to `inputs.json`, install miniconda3 and the \"cloud-data\" Python environment to all resources, and write randomly-generated files to all cloud storage locations (if any files were specified). If writing randomly-generated files, especially large ones, the execution of this cell may take a while."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb642c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "While randomly-generated files are written in parallel by default, if you wish to speed up the execution of this cell, consider creating/choosing a resource with more powerful worker nodes.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff33e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up workflow...\n",
      "Will install miniconda3 to \"/home/jgreen/.miniconda3\"\n",
      "Installing Miniconda-latest on \"gcptestnew\"...\n",
      "Miniconda is already installed in \"/home/jgreen/.miniconda3\"!\n",
      "Finished installing Miniconda on \"gcptestnew\".\n",
      "\n",
      "Building \"cloud-data\" environment on \"gcptestnew\"...\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipython\n",
      "    - python\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  asttokens          pkgs/main/noarch::asttokens-2.0.5-pyhd3eb1b0_0 \n",
      "  backcall           pkgs/main/noarch::backcall-0.2.0-pyhd3eb1b0_0 \n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0 \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.05.30-h06a4308_0 \n",
      "  decorator          pkgs/main/noarch::decorator-5.1.1-pyhd3eb1b0_0 \n",
      "  executing          pkgs/main/noarch::executing-0.8.3-pyhd3eb1b0_0 \n",
      "  ipython            pkgs/main/linux-64::ipython-8.12.0-py311h06a4308_0 \n",
      "  jedi               pkgs/main/linux-64::jedi-0.18.1-py311h06a4308_1 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_0 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "  matplotlib-inline  pkgs/main/linux-64::matplotlib-inline-0.1.6-py311h06a4308_0 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.10-h7f8727e_0 \n",
      "  parso              pkgs/main/noarch::parso-0.8.3-pyhd3eb1b0_0 \n",
      "  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3eb1b0_3 \n",
      "  pickleshare        pkgs/main/noarch::pickleshare-0.7.5-pyhd3eb1b0_1003 \n",
      "  pip                pkgs/main/linux-64::pip-23.2.1-py311h06a4308_0 \n",
      "  prompt-toolkit     pkgs/main/linux-64::prompt-toolkit-3.0.36-py311h06a4308_0 \n",
      "  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2 \n",
      "  pure_eval          pkgs/main/noarch::pure_eval-0.2.2-pyhd3eb1b0_0 \n",
      "  pygments           pkgs/main/linux-64::pygments-2.15.1-py311h06a4308_1 \n",
      "  python             pkgs/main/linux-64::python-3.11.4-h955ad1f_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-68.0.0-py311h06a4308_0 \n",
      "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0 \n",
      "  stack_data         pkgs/main/noarch::stack_data-0.2.0-pyhd3eb1b0_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 \n",
      "  traitlets          pkgs/main/linux-64::traitlets-5.7.1-py311h06a4308_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2023c-h04d1e81_0 \n",
      "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-pyhd3eb1b0_0 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.38.4-py311h06a4308_0 \n",
      "  xz                 pkgs/main/linux-64::xz-5.4.2-h5eee18b_0 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate cloud-data\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  abseil-cpp         conda-forge/linux-64::abseil-cpp-20211102.0-h27087fc_1 \n",
      "  arrow-cpp          pkgs/main/linux-64::arrow-cpp-11.0.0-h374c478_1 \n",
      "  aws-c-common       pkgs/main/linux-64::aws-c-common-0.6.8-h5eee18b_1 \n",
      "  aws-c-event-stream pkgs/main/linux-64::aws-c-event-stream-0.1.6-h6a678d5_6 \n",
      "  aws-checksums      pkgs/main/linux-64::aws-checksums-0.1.11-h5eee18b_2 \n",
      "  aws-sdk-cpp        pkgs/main/linux-64::aws-sdk-cpp-1.8.185-h721c034_1 \n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl \n",
      "  bokeh              conda-forge/noarch::bokeh-2.4.3-pyhd8ed1ab_3 \n",
      "  boost-cpp          pkgs/main/linux-64::boost-cpp-1.73.0-h7f8727e_12 \n",
      "  bottleneck         pkgs/main/linux-64::bottleneck-1.3.5-py311hbed6279_0 \n",
      "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py311h6a678d5_7 \n",
      "  c-ares             pkgs/main/linux-64::c-ares-1.19.0-h5eee18b_0 \n",
      "  click              conda-forge/noarch::click-8.1.6-unix_pyh707e725_0 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-2.2.1-pyhd8ed1ab_0 \n",
      "  cytoolz            pkgs/main/linux-64::cytoolz-0.12.0-py311h5eee18b_0 \n",
      "  dask               conda-forge/noarch::dask-2023.8.0-pyhd8ed1ab_0 \n",
      "  dask-core          conda-forge/noarch::dask-core-2023.8.0-pyhd8ed1ab_0 \n",
      "  distributed        conda-forge/noarch::distributed-2023.8.0-pyhd8ed1ab_0 \n",
      "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1 \n",
      "  fsspec             conda-forge/noarch::fsspec-2023.6.0-pyh1a96a4e_0 \n",
      "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004 \n",
      "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2 \n",
      "  glog               conda-forge/linux-64::glog-0.5.0-h48cff8f_0 \n",
      "  grpc-cpp           pkgs/main/linux-64::grpc-cpp-1.48.2-he1ff14a_1 \n",
      "  icu                conda-forge/linux-64::icu-58.2-hf484d3e_1000 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-6.8.0-pyha770c72_0 \n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-6.8.0-hd8ed1ab_0 \n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2023.1.0-hdb19cb5_46305 \n",
      "  jinja2             conda-forge/noarch::jinja2-3.1.2-pyhd8ed1ab_1 \n",
      "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_1 \n",
      "  krb5               pkgs/main/linux-64::krb5-1.20.1-h143b758_1 \n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 \n",
      "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 \n",
      "  libboost           pkgs/main/linux-64::libboost-1.73.0-h28710b8_12 \n",
      "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.0.9-h166bdaf_7 \n",
      "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.0.9-h166bdaf_7 \n",
      "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.0.9-h166bdaf_7 \n",
      "  libcurl            pkgs/main/linux-64::libcurl-8.1.1-h251f7ec_2 \n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_0 \n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20221030-h5eee18b_0 \n",
      "  libev              conda-forge/linux-64::libev-4.33-h516909a_1 \n",
      "  libevent           pkgs/main/linux-64::libevent-2.1.12-hdbd6064_1 \n",
      "  libnghttp2         pkgs/main/linux-64::libnghttp2-1.52.0-h2d74bed_1 \n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 \n",
      "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.20.3-he621ea3_0 \n",
      "  libssh2            pkgs/main/linux-64::libssh2-1.10.0-hdbd6064_2 \n",
      "  libthrift          pkgs/main/linux-64::libthrift-0.15.0-h1795dd8_2 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.5.0-h6a678d5_2 \n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_1 \n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_1 \n",
      "  locket             conda-forge/noarch::locket-1.0.0-pyhd8ed1ab_0 \n",
      "  lz4                pkgs/main/linux-64::lz4-4.3.2-py311h5eee18b_0 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_0 \n",
      "  markupsafe         pkgs/main/linux-64::markupsafe-2.1.1-py311h5eee18b_0 \n",
      "  mkl                pkgs/main/linux-64::mkl-2023.1.0-h213fc3f_46343 \n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py311h5eee18b_1 \n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.6-py311ha02d727_1 \n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py311ha02d727_1 \n",
      "  msgpack-python     pkgs/main/linux-64::msgpack-python-1.0.3-py311hdb19cb5_0 \n",
      "  numexpr            pkgs/main/linux-64::numexpr-2.8.4-py311h65dcdc2_1 \n",
      "  numpy              pkgs/main/linux-64::numpy-1.25.2-py311h08b1b3b_0 \n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.25.2-py311hf175353_0 \n",
      "  orc                pkgs/main/linux-64::orc-1.7.4-hb3bc3d3_1 \n",
      "  packaging          conda-forge/noarch::packaging-23.1-pyhd8ed1ab_0 \n",
      "  pandas             pkgs/main/linux-64::pandas-1.5.3-py311hba01205_0 \n",
      "  partd              conda-forge/noarch::partd-1.4.0-pyhd8ed1ab_0 \n",
      "  pillow             pkgs/main/linux-64::pillow-9.4.0-py311h6a678d5_0 \n",
      "  psutil             pkgs/main/linux-64::psutil-5.9.0-py311h5eee18b_0 \n",
      "  pyarrow            pkgs/main/linux-64::pyarrow-11.0.0-py311hd8e8d9b_0 \n",
      "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6 \n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0 \n",
      "  pytz               conda-forge/noarch::pytz-2023.3-pyhd8ed1ab_0 \n",
      "  pyyaml             pkgs/main/linux-64::pyyaml-6.0-py311h5eee18b_1 \n",
      "  re2                conda-forge/linux-64::re2-2022.04.01-h27087fc_0 \n",
      "  snappy             pkgs/main/linux-64::snappy-1.1.9-h295c915_0 \n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0 \n",
      "  tbb                pkgs/main/linux-64::tbb-2021.8.0-hdb19cb5_0 \n",
      "  tblib              conda-forge/noarch::tblib-1.7.0-pyhd8ed1ab_0 \n",
      "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0 \n",
      "  tornado            pkgs/main/linux-64::tornado-6.3.2-py311h5eee18b_0 \n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.7.1-pyha770c72_0 \n",
      "  urllib3            conda-forge/noarch::urllib3-2.0.4-pyhd8ed1ab_0 \n",
      "  utf8proc           pkgs/main/linux-64::utf8proc-2.6.1-h27cfd23_0 \n",
      "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2 \n",
      "  zict               conda-forge/noarch::zict-3.0.0-pyhd8ed1ab_0 \n",
      "  zipp               conda-forge/noarch::zipp-3.16.2-pyhd8ed1ab_0 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.05.30~ --> conda-forge::ca-certificates-2023.7.22-hbcca054_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask-jobqueue\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  dask-jobqueue      conda-forge/noarch::dask-jobqueue-0.8.2-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - xarray\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  xarray             conda-forge/noarch::xarray-2023.7.0-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - intake-xarray\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0 \n",
      "  asciitree          conda-forge/noarch::asciitree-0.3.3-py_2 \n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0 \n",
      "  cftime             pkgs/main/linux-64::cftime-1.6.2-py311hbed6279_0 \n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-3.2.0-pyhd8ed1ab_0 \n",
      "  curl               pkgs/main/linux-64::curl-8.1.1-hdbd6064_2 \n",
      "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0 \n",
      "  fasteners          conda-forge/noarch::fasteners-0.17.3-pyhd8ed1ab_0 \n",
      "  hdf4               conda-forge/linux-64::hdf4-4.2.15-h10796ff_3 \n",
      "  hdf5               conda-forge/linux-64::hdf5-1.10.6-nompi_h3c11f04_101 \n",
      "  idna               conda-forge/noarch::idna-3.4-pyhd8ed1ab_0 \n",
      "  intake             conda-forge/noarch::intake-0.7.0-pyhd8ed1ab_0 \n",
      "  intake-xarray      conda-forge/noarch::intake-xarray-0.7.0-pyhd8ed1ab_0 \n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-h14aa051_20 \n",
      "  libgfortran4       conda-forge/linux-64::libgfortran4-7.5.0-h14aa051_20 \n",
      "  libnetcdf          conda-forge/linux-64::libnetcdf-4.8.1-nompi_hcd642e3_100 \n",
      "  libzip             pkgs/main/linux-64::libzip-1.8.0-h6ac8c49_1 \n",
      "  netcdf4            pkgs/main/linux-64::netcdf4-1.6.2-py311h0e679e6_0 \n",
      "  numcodecs          pkgs/main/linux-64::numcodecs-0.11.0-py311h6a678d5_0 \n",
      "  requests           conda-forge/noarch::requests-2.31.0-pyhd8ed1ab_0 \n",
      "  zarr               conda-forge/noarch::zarr-2.16.0-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - fastparquet\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cramjam            pkgs/main/linux-64::cramjam-2.6.2-py311h52d8a92_0 \n",
      "  fastparquet        pkgs/main/linux-64::fastparquet-2023.4.0-py311hf4808d0_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - h5netcdf\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  h5netcdf           pkgs/main/linux-64::h5netcdf-1.2.0-py311h06a4308_0 \n",
      "  h5py               pkgs/main/linux-64::h5py-3.7.0-py311h021c08c_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.05.30-h06a4308_0 \n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2023.7.22-py311h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - gcsfs\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiohttp            pkgs/main/linux-64::aiohttp-3.8.3-py311h5eee18b_0 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0 \n",
      "  attrs              conda-forge/noarch::attrs-23.1.0-pyh71513ae_1 \n",
      "  blinker            conda-forge/noarch::blinker-1.6.2-pyhd8ed1ab_0 \n",
      "  cachetools         conda-forge/noarch::cachetools-4.2.4-pyhd8ed1ab_0 \n",
      "  cffi               pkgs/main/linux-64::cffi-1.15.1-py311h5eee18b_3 \n",
      "  cryptography       pkgs/main/linux-64::cryptography-41.0.2-py311h22a60cf_0 \n",
      "  frozenlist         pkgs/main/linux-64::frozenlist-1.3.3-py311h5eee18b_0 \n",
      "  gcsfs              conda-forge/noarch::gcsfs-2023.6.0-pyhd8ed1ab_0 \n",
      "  google-api-core    conda-forge/noarch::google-api-core-2.8.1-pyhd8ed1ab_0 \n",
      "  google-auth        conda-forge/noarch::google-auth-1.35.0-pyh6c4a22f_0 \n",
      "  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-1.0.0-pyhd8ed1ab_0 \n",
      "  google-cloud-core  conda-forge/noarch::google-cloud-core-2.3.3-pyhd8ed1ab_0 \n",
      "  google-cloud-stor~ conda-forge/noarch::google-cloud-storage-2.10.0-pyh1a96a4e_0 \n",
      "  google-crc32c      pkgs/main/linux-64::google-crc32c-1.5.0-py311h5eee18b_0 \n",
      "  google-resumable-~ conda-forge/noarch::google-resumable-media-2.5.0-pyhd8ed1ab_0 \n",
      "  googleapis-common~ conda-forge/noarch::googleapis-common-protos-1.60.0-pyhd8ed1ab_0 \n",
      "  grpcio             pkgs/main/linux-64::grpcio-1.48.2-py311he1ff14a_1 \n",
      "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0 \n",
      "  multidict          pkgs/main/linux-64::multidict-6.0.2-py311h5eee18b_0 \n",
      "  oauthlib           conda-forge/noarch::oauthlib-3.2.2-pyhd8ed1ab_0 \n",
      "  protobuf           pkgs/main/linux-64::protobuf-3.20.3-py311h6a678d5_0 \n",
      "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0 \n",
      "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0 \n",
      "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0 \n",
      "  pyjwt              conda-forge/noarch::pyjwt-2.8.0-pyhd8ed1ab_0 \n",
      "  pyopenssl          conda-forge/noarch::pyopenssl-23.2.0-pyhd8ed1ab_1 \n",
      "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0 \n",
      "  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.1-pyhd8ed1ab_0 \n",
      "  rsa                conda-forge/noarch::rsa-4.9-pyhd8ed1ab_0 \n",
      "  typing-extensions  conda-forge/noarch::typing-extensions-4.7.1-hd8ed1ab_0 \n",
      "  yarl               pkgs/main/linux-64::yarl-1.8.1-py311h5eee18b_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.05.30~ --> conda-forge::ca-certificates-2023.7.22-hbcca054_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/linux-64::certifi-2023.7.22~ --> conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0 \n",
      "  charset-normalizer conda-forge::charset-normalizer-3.2.0~ --> pkgs/main::charset-normalizer-2.0.4-pyhd3eb1b0_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - s3fs\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiobotocore        conda-forge/noarch::aiobotocore-2.5.0-pyhd8ed1ab_0 \n",
      "  aioitertools       conda-forge/noarch::aioitertools-0.11.0-pyhd8ed1ab_0 \n",
      "  botocore           pkgs/main/linux-64::botocore-1.29.76-py311h06a4308_0 \n",
      "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py311h5eee18b_1002 \n",
      "  jmespath           conda-forge/noarch::jmespath-1.0.1-pyhd8ed1ab_0 \n",
      "  s3fs               conda-forge/noarch::s3fs-2023.6.0-pyhd8ed1ab_0 \n",
      "  wrapt              pkgs/main/linux-64::wrapt-1.14.1-py311h5eee18b_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  urllib3                                2.0.4-pyhd8ed1ab_0 --> 1.26.15-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - matplotlib\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotli             conda-forge/linux-64::brotli-1.0.9-h166bdaf_7 \n",
      "  brotli-bin         conda-forge/linux-64::brotli-bin-1.0.9-h166bdaf_7 \n",
      "  contourpy          pkgs/main/linux-64::contourpy-1.0.5-py311hdb19cb5_0 \n",
      "  cycler             conda-forge/noarch::cycler-0.11.0-pyhd8ed1ab_0 \n",
      "  dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0 \n",
      "  expat              conda-forge/linux-64::expat-2.2.10-h9c3ff4c_0 \n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-hef1e5e3_0 \n",
      "  fonttools          pkgs/main/noarch::fonttools-4.25.0-pyhd3eb1b0_0 \n",
      "  glib               pkgs/main/linux-64::glib-2.69.1-he621ea3_2 \n",
      "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.1-h6a678d5_1 \n",
      "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.1-h5eee18b_1 \n",
      "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.4.4-py311h6a678d5_0 \n",
      "  libclang           pkgs/main/linux-64::libclang-10.0.1-default_hb85057a_2 \n",
      "  libllvm10          conda-forge/linux-64::libllvm10-10.0.1-he513fc3_3 \n",
      "  libpq              pkgs/main/linux-64::libpq-12.15-hdbd6064_1 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.15-h7f8727e_0 \n",
      "  libxkbcommon       pkgs/main/linux-64::libxkbcommon-1.0.1-hfa300c1_0 \n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.9.14-h74e7548_0 \n",
      "  libxslt            pkgs/main/linux-64::libxslt-1.1.35-h4e12654_0 \n",
      "  matplotlib         pkgs/main/linux-64::matplotlib-3.7.1-py311h06a4308_1 \n",
      "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.7.1-py311ha02d727_1 \n",
      "  munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 \n",
      "  nspr               pkgs/main/linux-64::nspr-4.35-h6a678d5_0 \n",
      "  nss                pkgs/main/linux-64::nss-3.89.1-h6a678d5_0 \n",
      "  pcre               conda-forge/linux-64::pcre-8.45-h9c3ff4c_0 \n",
      "  ply                conda-forge/noarch::ply-3.11-py_1 \n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.1.1-pyhd8ed1ab_0 \n",
      "  pyqt               pkgs/main/linux-64::pyqt-5.15.7-py311h6a678d5_0 \n",
      "  pyqt5-sip          pkgs/main/linux-64::pyqt5-sip-12.11.0-py311h6a678d5_0 \n",
      "  qt-main            pkgs/main/linux-64::qt-main-5.15.2-h327a75a_7 \n",
      "  qt-webengine       pkgs/main/linux-64::qt-webengine-5.15.9-hd2b0992_4 \n",
      "  qtwebkit           pkgs/main/linux-64::qtwebkit-5.212-h4eab89a_4 \n",
      "  sip                pkgs/main/linux-64::sip-6.6.2-py311h6a678d5_0 \n",
      "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.5.2\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgreen/.miniconda3/envs/cloud-data\n",
      "\n",
      "  added / updated specs:\n",
      "    - ujson\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ujson              pkgs/main/linux-64::ujson-5.4.0-py311h6a678d5_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> anaconda::ca-certificates-2023.01.10-h06a4308_0 \n",
      "  certifi            conda-forge::certifi-2023.7.22-pyhd8e~ --> anaconda::certifi-2020.6.20-pyhd3eb1b0_3 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Requirement already satisfied: pyarrow in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from pyarrow) (1.25.2)\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/b8/46/1d255bb55e63de02f7b2f3a2f71b59b840db21d61ff7cd41edbfc2da448a/scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from scipy) (1.25.2)\n",
      "Using cached scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.2 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.1\n",
      "Requirement already satisfied: google-auth-oauthlib in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (1.0.0)\n",
      "Collecting google-auth>=2.15.0 (from google-auth-oauthlib)\n",
      "  Obtaining dependency information for google-auth>=2.15.0 from https://files.pythonhosted.org/packages/9c/8d/bff87fc722553a5691d8514da5523c23547f3894189ba03b57592e37bdc2/google_auth-2.22.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth-oauthlib) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (1.26.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.miniconda3/envs/cloud-data/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2020.6.20)\n",
      "Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Installing collected packages: google-auth\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.35.0\n",
      "    Uninstalling google-auth-1.35.0:\n",
      "      Successfully uninstalled google-auth-1.35.0\n",
      "Successfully installed google-auth-2.22.0\n",
      "Finished building \"cloud-data\" environment on \"gcptestnew\".\n",
      "\n",
      "Done installing Miniconda-latest and building `cloud-data` on all requested resources.\n",
      "\n",
      "\n",
      "Generating random files (this will take a while for large size requests)...\n",
      "Generating NetCDF4...\n",
      "Writing data variable \"random1\"\\...\n",
      "Data variable \"random1\" written to \"./random_10.0GB_NetCDF4.nc\"\n",
      "Writing data variable \"random2\"\\...\n",
      "Data variable \"random2\" written to \"./random_10.0GB_NetCDF4.nc\"\n"
     ]
    }
   ],
   "source": [
    "print('Setting up workflow...')\n",
    "\n",
    "user_input = json.dumps({\"RESOURCES\" : resources,\n",
    "                         \"STORAGE\" : storage,\n",
    "                         \"USERFILES\" : user_files,\n",
    "                         \"RANDFILES\" : randfiles\n",
    "                        })\n",
    "\n",
    "with open('inputs.json', 'w') as outfile:\n",
    "    outfile.write(user_input)\n",
    "\n",
    "os.system(\"bash workflow_notebook_setup.sh\")\n",
    "\n",
    "print('Workflow setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05ea9b",
   "metadata": {},
   "source": [
    "## Step 3: Run Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40d260",
   "metadata": {},
   "source": [
    "### Convert File to Cloud-Native"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad150c9",
   "metadata": {},
   "source": [
    "Since one of the major goals of this benchmarking is testing legacy formats against cloud-native ones, we must convert your legacy-formatted data (CSV and NetCDF4) into their corresponding cloud-native formats. This cell will execute and time the conversion process, writing each new format in parallel. The conversion will be done using each cluster's full amount of resources, so be mindful of this feature when using clusters that are expensive to operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4685034",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"bash benchmarks-core/run_benchmark_step.sh \\\"convert-data.py\\\" \\\"conversions.csv\\\"\")\n",
    "df_conversions = pd.read_csv(os.getcwd() + '/results/csv-files/conversions.csv')\n",
    "df_conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702d935",
   "metadata": {},
   "source": [
    "### File Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffc4ec",
   "metadata": {},
   "source": [
    "The last computation-intensive test in the benchmarking is reading and timing files from cloud storage. This will give you an idea of what data transfer throughput you can expect when using cloud storage and different data formats in other workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"bash benchmarks-core/run_benchmark_step.sh \\\"read-data.py\\\" \\\"reads.csv\\\"\")\n",
    "df_reads = pd.read_csv(os.getcwd() + '/results/csv-files/reads.csv')\n",
    "df_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a169d8",
   "metadata": {},
   "source": [
    "## TODO: Step 4: Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d69914",
   "metadata": {},
   "source": [
    "**Feature not ready**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fb9e7",
   "metadata": {},
   "source": [
    "## Step 5: Remove Benchmarking Files from Cloud Resources (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"bash postprocessing/remove-benchmark-files.sh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
