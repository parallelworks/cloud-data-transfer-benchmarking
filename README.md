# cloud-data-transfer-benchmarking
## Overview
This repository is the start of a comprehensive benchmarking workflow designed to measure speeds of writing legacy file formats (e.g., NetCDF & CSV) to cloud storage, converting them to cloud-native formats (e.g., Zarr, Parquet, TileDB Embedded), reading both file classes, and performing operations using cloud-cluster computing and cloud storage. See the (benchmarking cloud data transfer project)[https://github.com/parallelworks/issues/issues/1196] for more information on where the workflow is in the creation process. Documentation will be updated as tasks are completed.
